# Гайд по брокерам сообщений
Пример: есть 5 сервисов и все они шлют уведомления на единственный сервис уведомлений. Им нужно знать, какой адрес у сервиса уведомлений. Сервис уведомлений может переехать и пришлось бы менять адрес во всех пяти сервисах.

Проблематика: во всех пяти сервисах эти уведмоления нигде не сохраняются, на сервис уведомлений может быть сильно большая нагрузка запросами, поэтому может не справиться.

Если сервис уведомлений навернётся, то может потерять все уведомления (либо, если критичнее - какие-либо транзакции). 

Все эти проблемы закрывает брокер сообщений - Kafka:
1. Все пять сервисов шлют уведомления не напрямую в сервис уведов, а в Kafka;
2. Брокер Kafka их принимает (часто в json) и сохраняет там.
3. Сервис уведомлений самостоятельно ходит в брокера и спрашивает есть ли новые сообщений и идёт исполнять. Возвращается за новой пачкой и т.д.
4. Теперь сервис уведомлений может быть развернут хоть где.
5. Брокер разворачивается на каком-то конкретном сервере или нескольких и все знают его адрес. Он никуда не переезжает.
6. Брокер связующее звено в микросервисной архитектуре.

Супер-простую очередь можно было бы реализовать просто через БД, например PostgreSQL, но очень много нюансов есть в брокерах сообщений, которые тяжело сделать через БД.

## Apache Kafka
Самый популярный брокер сообщений.
+ Выдерживает большую нагрузку (более 1млн запросов в секунду). 
+ Его легко масштабировать горизонтально (на новых серверах). 
+ Kafka хранит все данные, т.е. можно хранить месяц/год.
+ Kafka позволяет мигрировать из одной базы в другую.


## RabbitMQ
+ Его очень легко развернуть и поднять
+ Сообщение можно легко отложить (например, закинуть в конец очереди - в кафке это тяжелее).
+ Можно к очереди сообщений подключить любое количество консьюмеров (сервисы, которые считывают и потребляют эти сообщения), т.е. можно быстро раскидать сообщения, подключив много консьюмеров


## NATS
+ Позиционируется как замена вышеперечисленным брокерам
+ куча плагинов


## Уточнения
Через брокеры сообщений не перенаправляем какие-то супергигантские объёмы данных - обычные json'ы, строчки, уведы.


# KAFKA
## Ситуация
Есть пользователи, всякие фронтенды -> Бэкенд -> Сервер + БД.

Исторически программисты создавали бэки в виде монолитов (когда весь код в одном едином проекте на одном компе со всеми фичами).

Далее перешли к концепции микросервисов. Каждую из отдельных фич выносят в отдельный проект, который запускается на своем отдельном сервере.

Все микросервисы взаимодействуют не через код, а по "интернету" (самый популярный HTTP-протокол). Это имеет ряд проблем, поэтому часто используют не просто HTTP-передачу, но и брокеры сообщений, например Kafka - она появилась как решения проблем:
1. Все сети, в частности сеть-интернет, ненадёжные - могут на середине пропасть, быть не доставлены пользователю. Ответ тоже передаётся также обратно. Т.е. программа-отправитель должна ждать ответ, чтобы убедиться, что данные были точно отправлены. Если делать асинхронно, но тут другой нюанс, ответ может использоваться в долгой операции обработки данных, т.е. выполняться в памяти получателя. Тут есть риск потери данных, т.е. условно при перезапуске данные исчезнут просто. 
2. Могут быть ещё приложений (микросервисов), куда из приложения №1 тоже нужно посылать те же самые данные. Нужно в прил.1 указывать куда посылать ещё. Чем больше таких приложух появится - тем больше дополнительного кода в приложении-отправителе. Т.е. те же самые сетевые операции, риск в Х раз больше.

Для решения этих проблем появились брокеры сообщений.

## Что такое брокер сообщений
Промежуточное звено, которое может подсохранить в себе какие-то данные и оттуда забираются получателем. Т.е. "придерживаем в середине".

Брокер сообщений - специальная программа, которая запускается на обычном сервере. Программа-получатель постоянно опрашивает брокера на предмет того, есть ли для неё новые данные, которые надо обработать. Если такие данные появились - то брокер отдаёт его на обработку.

## Продьюсеры и консьюмеры
Программа-отправитель: продьюсер
Программа-получатель: консьюмер (потребитель)

## Преимущества брокера
1. Можем обрабатывать данные по-настоящему асинхронно. Брокер сообщения говорит, что 100% данные поймал и подсохранил у себя и гарантирует, что доставит.
2. Микросервис нотификаций забирает у брокера данные, когда будет готов.
3. Брокер сообщений все данные сохраняет у себя, если консьюмер сгорит во время обработки важной операции. Когда перезапустим консьюмера, то снова приходит к брокеру и просит необработанные сообщения.
4. Ситуация "один продьюсер -> много потребителей". Теперь продьюсер работает только с брокером.

## Фичи Kafka
1. Типы сообщений может быть много (уведы о лайках, комментах, подписках и т.д.) - поэтому в Кафке существует понятие ТОПИКОВ.

ТОПИК - это "тема" или "КАНАЛ". Т.е. внутри кафки можно создать кучу топиков, т.е. "каналов", которые мы создаём для сообщений определенного ТИПА. Таким образом консьюмеры не путаются в сообщениях, есть чёткие ожидания.

Например, создаём топик для сообщение о постах, о создании групп в соц. сетях, о лайках, о реакциях и так далее. 

2. Каждый микросервис может быть одновременно и продьюсером и консьюмером.

# Гарантии
## Если сети ненадёжны, может ли возникнуть та же самая проблема с HTTP-взаимодействием?
Да, но у Kafkи есть определенные гарантии. Мы можем её настроить так, чтобы она гарантировала определенный формат доставки сообщений. Можем ей сказать
1. Гарантия **"at most once"** (максимум один раз), лучше подумать в сторону Redis:
**Что говорим**: "Гарантируй, что сообщения, которые я в неё публикую, будут доставлены консьюмеру МАКСИМУМ 1 раз". 
**Что делает**: При таких настройках кафки если на середине передачи до брокера происходит ошибка, то продьюсер пойдёт дальше, а кафка ему не сообщит ничего. Т.е. сообщения могут просто теряться.
**Зачем**: когда передаём данные по аналитике, например если потеряем один клик пользователя, то особо ни на чём не скажется. Когда не особо критичные вещи + знаем что такое не постоянно будет происходить. При такой конфигурации КАФКА будет работать шустрее и экономит память.

2. Гарантия **"at least once"** - минимум ОДИН раз, очень важная гарантия:
**Что говорим**: гарантируй, что любое сообщение будет доставлено получателю минимум один раз (т.е. 1 раз точно, но может и больше).  
**Что делает**: Продьюсер какое-то время будет ждать ответа (acknowledgement / акноледжа / ака) от Кафки о том, что Кафка их получила. Как только брокер получит, то продьюсер идёт раньше и уверен что данные записались в Кафку. А кафка отправит подтверждение только когда данные получила и подсохранила у себя. Если продьюсер не получил ответа о подсохранении, то отправит ещё раз, пока не получит подтверждение.
**Зачем**: Гарантируем, что данные точно в Кафку доставятся и подсохранятся на жесткий диск. Т.е. данные точно не потеряются
**Недостаток**: Кафка забрала у продьюсера и должна отправить подтверждение обратно - происходит ошибка HTTP. Поэтому продьюсер отправит копию тех же данных ещё раз. Кафка опять запишет на диск, допустим доставит ответ продюсеру, но сообщение ЗАДУБЛИРОВАЛОСЬ. Теперь в кафке будет два дубликата и оба будут потреблены на другой стороне. Она не умеет удалять дубликат. Т.е. консьюмер должен правильно обрабатывать дубликат.

3. **Exactly-once** (ровно 1 раз):
Сильно сложнее в распределенных системах чтобы доставить что-то ровно один раз. В кафке 4+ это стало возможно благодаря распределенным транзакциям (но тут сильно глубоко нужно разбираться).

## Что такое идемпотентность
Всегда подразумеваем вероятность дубликата, значит должен быть фильтр дубликатов на стороне консьюмера. Т.е. КОНСЬЮМЕР ДОЛЖЕН БЫТЬ ИДЕМПОТЕНТНЫМ. Часто встречается на собесах данный вопрос. Т.е. способность сервиса обрабатывать данные так, как будто они единожды туда пришли, т.е. результат будет таким же, как при однократной обработке.

Гарантии идемпотентности:

## Что делать если Кафка умрёт
Никто и никогда не запускает программы на одном сервере. Ставим ещё одну кафку на второй сервер с той же самой конфигурацией и топиками. Группа таких серверов - называется кластером (группа серверов с одной и той же программой).

Когда мы публикуем данные в кафку из продьюсера, то данные отправляются также и на второй. Если один сгорит, второй останется. ЭТО ПРИНЦИП РЕПЛИКАЦИИ. Желательно минимум три машины.

## Кажется, что не используется потенциал второго сервера
Тут самое ГЛАВНОЕ преимущество Кафки - то почему его используют во многих компаниях - ПАРТИШИНЫ И МАСШТАБИРОВАНИЕ КАФКИ.

## Что такое ПАРТИШИОНЫ (partitions)?
В кафке каждый топик поделён на партиции (типа части). Т.е. внутри канала есть ещё маленькие части. Все эти партишины содержат данные одного типа. Например, только данные о постах, но само сообщение попадёт в единственный партишин (напр., partition_3). Значит другие сообщения будут более менее равномерно распределяться по подканалам этого топика и двигаться к консьюмеру.

ПОРЯДОК ЗАПИСИ И ПОРЯДОК ЧТЕНИЯ в/из ПАРТИШНОВ СЛУЧАЙНЫ !!!

**ЗАЧЕМ?**
Мы данные можем параллельно в 5 подканалов публиковать и параллельно их забирать на другой стороне. Ну а если у нас один подканал, то данные последовательно забиваются как в очередь. Увеличивается пропускная способность. Т.е. если 5 параллельных - то публикаем в 5 параллельных каналов и забирать, т.е. это увеличит пропускную способность.

В разных потоков мы можем забирать с разных партишнов эти сообщения и не ждать последовательно обработки, если бы был один подканал топика.

Нарушает порядок следования сообщений друг за другом.

Если хотим последовательно, то в сообщение надо добавить доп. инфу в виде ключа в json, и говорим что если в разделе "ключ" имеют одно и то же значение, то направлен в один и тот же партишн.

Параллельно используется по дефолту.

### Если у нас два сервака с кафкой
То можем сказать перенести два подканала из пяти на вторую кафку второго сервера. И тогда получится, что данные, отправляясь в кафку будут идти на разные физические сервера что увеличит пропускную способность. 

### Если каждое сообщение летит в отдельную партицию, то получается при распределении данных если один из серверов ломается, то данные с этих партишенов потеряются?
Когда вы разносите топик по разным серверам, т.е. раскладываем разные партишены по разным серверам, то на самом деле, кроме этого, на другой машине оставляем копию этого партишена.

Таким образом, когда публикуем сообщение в партишен на основной машине, то копию этого сообщения публикуем в копию этого партишена на другой сервер. Консьюмер забирает это сообщение с основного сервера, а тот нужен для репликации данных.

Продюсер получает подтверждение от кафки только когда основной партишен обновлён и копия этого партишена обновлена.

Это то, зачем партишены существуют.